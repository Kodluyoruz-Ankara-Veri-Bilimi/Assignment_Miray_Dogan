{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Miray\\\\Desktop'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir( \"C:/Users/Miray/Desktop\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bu notebook ne yazık ki tamamlanamamıştır :-( \n",
    "Tuning kısımları bulunamamaktadır. Fakat derste gördüğümüz tüm adımlar ödevlerim içerisinde yer almaktadır.\n",
    "Hedefim; proje sunumları bitmeden tamamlamaktır.**\n",
    "Data hakkında info,visualize, hipotez testleri, model fit etme, classification ve regression modellerinden ve Kmeans'tan oluşan class'lar bulunmaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_information:\n",
    "        import pandas as pd\n",
    "        \n",
    "        \n",
    "        def __init__(self, data, usecols=None):\n",
    "            self.dataframe = pd.read_csv(data, usecols=usecols)\n",
    "            \n",
    "        def head(self,row=None):\n",
    "            return self.dataframe.head(row)\n",
    "        def tail(self,row=None):\n",
    "            return self.dataframe.tail(row)  \n",
    "    \n",
    "        def describe(self, transpoze = False):\n",
    "            if(transpoze == True):\n",
    "                dataf = self.dataframe.describe().T\n",
    "                return dataf\n",
    "            else:\n",
    "                 return self.dataframe.describe() \n",
    "        def info(self): \n",
    "            print(self.dataframe.info())   \n",
    "        def crosstab(self, col1, col2, normalize=None):\n",
    "            return pd.crosstab(index=self.dataframe[str(col1)], columns=self.dataframe[str(col2)], normalize=normalize)\n",
    "        def count(self):\n",
    "            return self.dataframe.count()\n",
    "        def isna(self):\n",
    "            return self.dataframe.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_visualizer:\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.dataframe = data\n",
    "        \n",
    "    def scatterplot(self,x,y,z=None):\n",
    "        scatter=sns.scatterplot(x = x, y = y, hue=z, data= self.dataframe)\n",
    "        return scatter\n",
    "    \n",
    "    def distplot(self, data):\n",
    "        distplot=sns.distplot(data)\n",
    "        return displot\n",
    "    def boxplot(self,x,y,z=None):\n",
    "        boxplot=sns.boxplot(x=x,y=y, hue=z, data= self.dataframe)\n",
    "        return boxplot\n",
    "    def catplot(self,x,y,z=None):\n",
    "        catplot= sns.catplot(x =x, y=y, hue=z, data=self.dataframe)  \n",
    "        return catplot\n",
    "    def lmplot(self,x,y,z= None):\n",
    "        lmplot= sns.lmplot(x = x, y= y, hue=z, data=self.dataframe)\n",
    "        return lmplot\n",
    "    def corr(self,data):\n",
    "        corr = data.corr()\n",
    "        colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "        heatmap=sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n",
    "        return heatmap\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_preprocessing:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    def __init__(self, data):\n",
    "        self.dataframe = data\n",
    "    def dropna(self):\n",
    "        return self.dataframe.dropna()\n",
    "    def dropColumn(self, column, axis=1):\n",
    "        self.dataframe = self.dataframe.drop(columns=[], axis=axis)\n",
    "    def get_dummies(self,data,prefix=None,prefix_sep='_',dummy_na=True, dtype=None):\n",
    "        dms=pd.get_dummies(data)\n",
    "        return dms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyptest:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.dataframe = data\n",
    "    def shapiro(self,data):\n",
    "        from scipy import stats\n",
    "        stat,p=stats.shapiro(self.data)\n",
    "        alpha=0.05 #kabul edilebilir hata miktarıdır.\n",
    "        if(p>alpha):\n",
    "            \n",
    "            print(\"Örneklem Normal (Gaussian) Dağılımdan gelmektedir, \"\"(Fail to Reject H0) \", \"Statistics=%.3f, p=%.3f\" % (stat,p))\n",
    "        else:\n",
    "            print(\"Örneklem Normal (Gaussian) Dağılımdan gelmemektedir\"\"( Reject H0)\",\"Statistics=%.3f, p=%.3f\" % (stat,p))\n",
    "    def levene(self,variable=None,x=None,y=None):#varyans homojenliği hipotezi testi. Varyanslar homojendir:H0  \n",
    "    \n",
    "        grps=pd.unique(data[variable].values)\n",
    "        df_numeric=self.data.select_dtypes(include=['float64','int64'])\n",
    "        for i in df_numeric.columns:\n",
    "            for j in grps:\n",
    "                df_new = data.dropna(subset=[i])\n",
    "                stat, p = stats.levene(df_new[i][data[variable]==X],df_new[i][data[variable]==y])\n",
    "                print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))\n",
    "                alpha = 0.05\n",
    "                if p>alpha:\n",
    "                    print(i,j,\" için varyans homojendir. (Fail to Reject H0)\")\n",
    "                else:\n",
    "                    print(i,j,\" için varyans homojen degildir. (reject H0)\")\n",
    "      \n",
    "    def chisquare(self,X,y):\n",
    "    from scipy.stats import chi2_contingency\n",
    "        pass #bağımlı ve bağımsız değişken kategorik olduğu zaman uyguladığımız hipotez testidir.\n",
    "    def spearmanr(self): #korelasyon anlamlılığı testi,normal dağılımdan gelmediğinde\n",
    "        pass\n",
    "    def pearson(self): #korelasyon anlamlılığı testi,normal dağılımdan geldiğinde\n",
    "        pass\n",
    "    def ttest_ind(self,X,y):\n",
    "        from scipy import stats\n",
    "        stat,p= stats.ttest_ind(self.X,self.y)\n",
    "        alpha=0.05\n",
    "        if(p>alpha):\n",
    "            print(\"Aralarındaki ilişki anlamsızdır\", \"hipotez kabul edilir\",\"Statistics=%.3f, p=%.3f\" % (stat,p))\n",
    "        else:\n",
    "            print(\"Aralarındaki ilişki anlamlıdır.\",\"hipotez reddedilir\",\"Statistics=%.3f, p=%.3f\" % (stat,p))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def model_fitting(self,norm = False, split = False, rate = 0.30, rs = 42):\n",
    "        \n",
    "        \n",
    "            from sklearn.model_selection import train_test_split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = rate, random_state = rs)\n",
    "            self.X_train = X_train\n",
    "            self.y_train = y_train\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            return \n",
    "      \n",
    "        print(\"Model fit edildi\", split \" + str(split))\n",
    "        \n",
    "\n",
    "    def roc_curve_test(self):\n",
    "        from sklearn.metrics import roc_auc_score,roc_curve\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        logit_roc_auc = roc_auc_score(self.y_test, self.classifier.predict(self.X_test)) \n",
    "        fpr, tpr, thresholds = roc_curve(self.y_test, self.classifier.predict_proba(self.X_test)[:,1]) \n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "        \n",
    "    def roc_curve_train(self):\n",
    "        from sklearn.metrics import roc_auc_score,roc_curve\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        logit_roc_auc = roc_auc_score(self.y_train, self.classifier.predict(self.X_train)) \n",
    "        fpr, tpr, thresholds = roc_curve(self.y_train, self.classifier.predict_proba(self.X_train)[:,1]) \n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "    def accuracy_test(self):\n",
    "        y_pred_test = self.classifier.predict(self.X_test)\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        print(accuracy_score(y_pred_test,self.y_test))\n",
    "        print(confusion_matrix(self.y_test, y_pred_test))\n",
    "    def accuracy_train(self):\n",
    "        y_pred_train = self.classifier.predict(self.X_train)\n",
    "        from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "        print(accuracy_score(y_test_pred,self.y_test))\n",
    "        print(confusion_matrix(self.y_test, y_test_pred))\n",
    "    \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_classification():\n",
    "    \n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "      \n",
    "        \n",
    "    def split(self, random_state=42): \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train , y_test = train_test_split(X,y,test_size = 0.3, random_state=42)\n",
    "        return\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     def non_tuning(self): #Bildiğimiz classification yöntemlerini hiçbir hyperparametre değiştirmeden uyguluyor\n",
    "        \n",
    "        from warnings import filterwarnings\n",
    "\n",
    "\n",
    "        filterwarnings('ignore')\n",
    "        from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        from xgboost import XGBClassifier\n",
    "        from lightgbm import LGBMClassifier\n",
    "        from catboost import CatBoostClassifier\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "        from sklearn.metrics import classification_report, accuracy_score\n",
    "        \n",
    "        self.accuracy = []\n",
    "        \n",
    "        \n",
    "\n",
    "        loj = LogisticRegression()\n",
    "        loj.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=loj.predict(self.X_train)\n",
    "        print('Loj Train Sonuçları')\n",
    "        print(classification_report(self.y_train,y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train,y_pred_train))\n",
    "        y_pred_test = loj.predict(self.X_test)\n",
    "        print('Loj Test Sonuçları')\n",
    "        print(classification_report(self.y_test,y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test,y_pred_test))\n",
    "       \n",
    "            \n",
    "        cart = DecisionTreeClassifier()\n",
    "        cart.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=cart.predict(self.X_train)\n",
    "        print('CART Train Sonuçları')\n",
    "        print(classification_report(self.y_train,y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train,y_pred_train))\n",
    "        y_pred_test = cart.predict(self.X_test)\n",
    "        print('CART Test Sonuçları')\n",
    "        print(classification_report(self.y_test,y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test,y_pred_test))\n",
    "        \n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=rf.predict(self.X_train)\n",
    "        print('Random Forest Train Sonuçları')\n",
    "        print(classification_report(self.y_train,y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train,y_pred_train))\n",
    "        y_pred_test = rf.predict(self.X_test)\n",
    "        print('Random Forest Test Sonuçları')\n",
    "        print(classification_report(self.y_test,y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test,y_pred_test))\n",
    "        \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)\n",
    "        X_train_scaled = scaler.transform(self.X_train)\n",
    "        X_test_scaled = scaler.transform(self.X_test)\n",
    "                \n",
    "        mlp = MLPClassifier()\n",
    "        mlp.fit(X_train_scaled,self.y_train)\n",
    "        y_pred_train=mlp.predict(X_train_scaled)\n",
    "        print('Yapay Sinir Ağı Train Sonuçları')\n",
    "        print(classification_report(self.y_test,y_pred))\n",
    "        self.accuracy.append(accuracy_score(self.y_train,y_pred_train))\n",
    "        y_pred_test = mlp.predict(X_test_scaled)\n",
    "        print('Yapay Sinir Ağı Test Sonuçları')\n",
    "        print(classification_report(self.y_test,y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test,y_pred_test))\n",
    "       \n",
    "\n",
    "        svc = SVC()\n",
    "        svc.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = svc.predict(self.X_train)\n",
    "        print('SVC train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = svc.predict(self.X_test)\n",
    "        print('SVC test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "       \n",
    "\n",
    "        gb = GradientBoostingClassifier()\n",
    "        gb.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = gb.predict(self.X_train)\n",
    "        print('Gradient Boosting train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = gb.predict(self.X_test)\n",
    "        print('Gradient Boosting test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "        \n",
    "        xgb = XGBClassifier().\n",
    "        xgb.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = xgb.predict(self.X_train)\n",
    "        print('XGBoosting train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = xgb.predict(self.X_test)\n",
    "        print('XGBoosting test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "\n",
    "        lgb = LGBMClassifier()\n",
    "        lgb.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = lgb.predict(self.X_train)\n",
    "        print('LGBMBoosting train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = lgb.predict(self.X_test)\n",
    "        print('LGBMBoosting test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "\n",
    "\n",
    "        cat = CatBoostClassifier()\n",
    "        cat.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = cat.predict(self.X_train)\n",
    "        print('CATBoosting train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = cat.predict(self.X_test)\n",
    "        print('CATBoosting test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(self.X_train, self.y_train)\n",
    "        y_pred_train = knn.predict(self.X_train)\n",
    "        print('KNN train seti sonuçları')\n",
    "        print(classification_report(self.y_train, y_pred_train))\n",
    "        self.accuracy.append(accuracy_score(self.y_train, y_pred))\n",
    "        y_pred_test = knn.predict(self.X_test)\n",
    "        print('KNN test seti sonuçları')\n",
    "        print(classification_report(self.y_test, y_pred_test))\n",
    "        self.accuracy.append(accuracy_score(self.y_test, y_pred_test))\n",
    "\n",
    "\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_regression():\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "       \n",
    "    def split(self, random_state=42, shuffle =shuffle ): #zaman serisi tipi datalar için False\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        if shuffle=False:\n",
    "            X_train, X_test, y_train , y_test = train_test_split(self.X,self.y,test_size = 0.3, random_state=rs)\n",
    "        else:\n",
    "            X_train, X_test, y_train , y_test = train_test_split(self.X,self.y,test_size = 0.3,random_state=rs)\n",
    "            \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    \n",
    "\n",
    "    def non_tuning_reg(self): \n",
    "        \n",
    "        from warnings import filterwarnings\n",
    "\n",
    "\n",
    "        filterwarnings('ignore')\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        from xgboost import XGBRegressor\n",
    "        from lightgbm import LGBMRegressor\n",
    "        from catboost import CatBoostRegressor\n",
    "        from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "        self.rms[]\n",
    "\n",
    "        Lin_reg = LinearRegression()\n",
    "        lin_reg.fit(self.X_train,self.y_train)\n",
    "        y_pred_train = lin_reg.predict(self.X_train)\n",
    "        print('LinearRegression Train sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=lin_reg.predict(self.X_test)\n",
    "        print('LinearRegression Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        \n",
    "        cart = DecisionTreeRegressor()\n",
    "        cart.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=cart.predict(self.X_train)\n",
    "        print('Cart Train sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=cart.predict(self.X_test)\n",
    "        print('Cart Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "\n",
    "        rfr = RandomForestRegressor()\n",
    "        rfr.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=rfr.predict(self.X_train)\n",
    "        print('Random Forest Train sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=rfr.predict(self.X_test)\n",
    "        print('Random Forest Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "       \n",
    "        \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)\n",
    "        X_train_scaled = scaler.transform(self.X_train)\n",
    "        X_test_scaled = scaler.transform(self.X_test)\n",
    "                \n",
    "        mlpr = MLPRegressor()\n",
    "        mlpr.fit(X_train_scaled,self.y_train)\n",
    "        y_pred_train=mlpr.predict(self.X_train_scaled)\n",
    "        print('Yapay Sinir Ağı Train sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=mlpr.predict(self.X_test_scaled)\n",
    "        print('Yapay Sinir Ağı Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "       \n",
    "\n",
    "        from sklearn.svm import SVR\n",
    "        svr=SVR()\n",
    "        svr.fit(self.X_train,self.y_train)\n",
    "        y_pred_train=svr.predict(self.X_train)\n",
    "        print('SVM Train sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=svr.prediction(self.X_test)\n",
    "        print('SVM Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "       \n",
    "\n",
    "      \n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(self.X_train, self.Y_train)\n",
    "        y_pred_train=gbr.predict(self.X_train)\n",
    "        print('GradientBoosting Train Sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=gbr.predict(self.X_test)\n",
    "        print('GradientBoosting Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "       \n",
    "\n",
    "        xgb = XGBRegressor()\n",
    "        xgb.fit(self.X_train, self.y_train)\n",
    "        y_pred_train=xgb.predict(self.X_train)\n",
    "        print('XGBoosting Train Sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=xgb.predict(self.X_test)\n",
    "        print('XGBoosting Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        \n",
    "        lgbm = LGBMRegressor()\n",
    "        lgbm.fit(self.X_train, self.y_train)\n",
    "        y_pred_train=lgbm.predict(self.X_train)\n",
    "        print('LGBMBoosting Train Sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=lgbm.predict(self.X_test)\n",
    "        print('KGBMBoosting Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        \n",
    "\n",
    "        cat = CatBoostRegressor()\n",
    "        cat.fit(self.X_train, self.y_train)\n",
    "        y_pred_train=cat.predict(self.X_train)\n",
    "        print('CatBoosting Train Sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=cat.predict(self.X_test)\n",
    "        print('CatBoosting Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "    \n",
    "       \n",
    "        knn = KNeighborsRegressor()\n",
    "        knn.fit(self.X_train, self.y_train)\n",
    "        y_pred_train=knn.predict(self.X_train)\n",
    "        print('KNN Train Sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_train,y_pred_train)))\n",
    "        y_pred_test=knn.predict(self.X_test)\n",
    "        print('KNN Test sonucu ')\n",
    "        print(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n",
    "        rms.append(np.sqrt(mean_squared_error(self.y_test,y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_means(): #Kaynak:https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "\n",
    "\n",
    "     def __init__(self,x,y):\n",
    "                  self.x = x\n",
    "                  self.y = y\n",
    "                     print(\"KMeans\")\n",
    "\n",
    "\n",
    "\n",
    "    def kmeans(data, k):\n",
    "\n",
    "    # Initialize centroids randomly\n",
    "        numFeatures = data.getNumFeatures()\n",
    "        centroids = getRandomCentroids(numFeatures, k)\n",
    "    \n",
    "    # Initialize book keeping vars.\n",
    "        iterations = 0\n",
    "        oldCentroids = None\n",
    "    \n",
    "    # Run the main k-means algorithm\n",
    "          while not shouldStop(oldCentroids, centroids, iterations):\n",
    "        # Save old centroids for convergence test. Book keeping.\n",
    "          oldCentroids = centroids\n",
    "             iterations += 1\n",
    "        \n",
    "        # Assign labels to each datapoint based on centroids\n",
    "          labels = getLabels(dataSet, centroids)\n",
    "        \n",
    "        # Assign centroids based on datapoint labels\n",
    "          centroids = getCentroids(data, labels, k)\n",
    "        \n",
    "    # We can get the labels too by calling getLabels(dataSet, centroids)\n",
    "          return centroids\n",
    "# Function: Should Stop\n",
    "# -------------\n",
    "# Returns True or False if k-means is done. K-means terminates either\n",
    "# because it has run a maximum number of iterations OR the centroids\n",
    "# stop changing.\n",
    "    def shouldStop(oldCentroids, centroids, iterations):\n",
    "         if iterations > MAX_ITERATIONS: return True\n",
    "            return oldCentroids == centroids\n",
    "# Function: Get Labels\n",
    "# -------------\n",
    "# Returns a label for each piece of data in the dataset. \n",
    "    def getLabels(data, centroids):\n",
    "    # For each element in the dataset, chose the closest centroid. \n",
    "    # Make that centroid the element's label.\n",
    "# Function: Get Centroids\n",
    "# -------------\n",
    "# Returns k random centroids, each of dimension n.\n",
    "    def getCentroids(data, labels, k):\n",
    "    # Each centroid is the geometric mean of the points that\n",
    "    # have that centroid's label. Important: If a centroid is empty (no points have\n",
    "    # that centroid's label) you should randomly re-initialize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Eksik kod kısımları güncellenecektir.* :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
